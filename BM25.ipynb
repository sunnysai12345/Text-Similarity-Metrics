{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assuming documents that are to be ranked are given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sample example\n",
    "docs=[\"How to learn Natural Language Processing\",\"How to get started with deeplearning for natural language processing\",\"Ultimate guide to understand and implement Natural language processing\",\"what are the prerequisites for learning Natural language processing\",\"Totally irreleavnt example\",\"Not a good examples\",\"This is how you should learn\",\"How not to learn NLP\"]\n",
    "queries=[\"how to start with natural language processing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A more concrete example using dataset of finding duplicate questions on quora contest \n",
    "df=pd.read_csv(\"data/train.csv\")\n",
    "queries=list(df[\"question1\"][:10])\n",
    "docs=list(df[\"question2\"][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N=len(docs) #Total number of documents that are to be ranked\n",
    "avgdl=sum([len(doc) for doc in docs])/len(docs) #average document length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert words to lower\n",
    "docs=[doc.lower() for doc in docs]\n",
    "queries=[query.lower() for query in queries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We are proceeding with docs and queries given in form of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def idf(query_word):\n",
    "    nd_qw=sum([1  for doc in docs if query_word in doc]) #Number of documents containing this word\n",
    "    up=N-nd_qw+0.5\n",
    "    down=nd_qw+0.5\n",
    "    #idf=np.log2(up/down)\n",
    "    #print(float(np.log(up/down)))\n",
    "    return float(np.log2(up/down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf(query_word,document):\n",
    "    return sum([1 for word in document.split() if word==query_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters set to standard value\n",
    "k1=1.2\n",
    "b=0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bm25(query,document):\n",
    "    score_qw=[]\n",
    "    for query_word in query.split():\n",
    "        #print(query_word,idf(query_word),tf(query_word,document))\n",
    "        up=idf(query_word)*tf(query_word,document)*(k1+1)\n",
    "        down=tf(query_word,document)+k1*(0.25+b*(len(document.split())/avgdl))\n",
    "        score_qw.append(up/down)\n",
    "    #print(score_qw)\n",
    "    return sum(score_qw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can notice that bm25 is giving high score for documents having high word co-occurence count with the query :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This is just for your understanding it wont much help for the contest\n",
    "for query in queries[:2]:\n",
    "    #Only for the top 2 queries\n",
    "    dscore=[]\n",
    "    for doc in docs:\n",
    "        dscore.append(bm25(query,doc))\n",
    "    print(dscore[:10]) #Output restricted to see scores of the first 10 docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
